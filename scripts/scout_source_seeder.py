import re
import os

def extract_sources_from_markdown(file_path):
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()

    # Regex to find table rows with URLs
    # Pattern: | **Name** | URL | ... |
    # Or: | Name | URL | ... |
    table_pattern = re.compile(r'\| (.*?) \| (.*?) \| (.*?) \|')
    
    sources = []
    lines = content.split('\n')
    for line in lines:
        match = table_pattern.search(line)
        if match:
            # Clean up the name and URL
            name = match.group(1).replace('**', '').strip()
            url = match.group(2).strip()
            
            # Skip header rows
            if name.lower() == 'source' or name.lower() == 'outlet' or name.lower() == 'organization' or name.lower() == 'agency':
                continue
            if '---' in name or '---' in url:
                continue
            
            # Simple URL validation (must contain http or www)
            if 'http' in url or 'www' in url:
                if not url.startswith('http'):
                    url = 'https://' + url
                sources.append({'name': name, 'url': url})
    
    return sources

def generate_sql(sources):
    sql_header = """-- CEKA Omni-Scout: Universal Source Seeder
-- Generated by scout_source_seeder.py

INSERT INTO public.scraper_sources (name, url, status, frequency_hours)
VALUES
"""
    sql_rows = []
    for s in sources:
        name = s['name'].replace("'", "''")
        url = s['url'].replace("'", "''")
        sql_rows.append(f"('{name}', '{url}', 'active', 24)")

    sql_body = ",\n".join(sql_rows)
    sql_footer = "\nON CONFLICT (name) DO UPDATE SET url = EXCLUDED.url;\n"
    
    return sql_header + sql_body + sql_footer

def main():
    # Correct path to the source file
    source_file = r"d:\CEKA\ceka v010\CONTEXT - CEKA\# ðŸš¨ COMPREHENSIVE MASTER LIST ALL LINKS - URLS.txt"
    output_file = r"d:\CEKA\ceka v010\CEKA\scripts\seed_sources.sql"
    
    if not os.path.exists(source_file):
        print(f"Error: Source file not found at {source_file}")
        return

    print(f"Parsing sources from {source_file}...")
    sources = extract_sources_from_markdown(source_file)
    print(f"Found {len(sources)} sources.")

    if not sources:
        print("No sources found. Check the regex or file content.")
        return

    sql_content = generate_sql(sources)
    
    os.makedirs(os.path.dirname(output_file), exist_ok=True)
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(sql_content)
    
    print(f"Successfully generated SQL seeder at {output_file}")

if __name__ == "__main__":
    main()
