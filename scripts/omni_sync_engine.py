import os
import json
import logging
import requests
import uuid
from datetime import datetime
from typing import List, Dict, Any, Optional

# ==============================================================================
# CEKA SOVEREIGN SYNCHRONIZER: THE ATTUNED ORCHESTRATOR (PRODUCTION GRADE)
# Mission: Absolute Factual Rigor, Constitutional Sentinel, Griot Composition.
# ==============================================================================

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - [SOVEREIGN-MIND-ORCHESTRATOR] - %(levelname)s - %(message)s'
)

class AttunedSynchronizer:
    def __init__(self, api_key: str):
        self.api_key = api_key
        # Using Gemini 1.5 Pro for Military Grade Reasoning
        self.api_url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro:generateContent?key={self.api_key}"
        self.prompt_path = "C:/Users/Administrator/.gemini/antigravity/brain/fabb9d5c-c69c-4a7d-b9cd-409e4a5ce4b8/sovereign_mind_prompt.md"
        self.output_sql = "scripts/attuned_intelligence_feed.sql"
        self._load_master_prompt()

    def _load_master_prompt(self):
        try:
            with open(self.prompt_path, 'r', encoding='utf-8') as f:
                self.master_prompt = f.read()
            logging.info("üìú Attuned Master Prompt loaded successfully.")
        except Exception as e:
            logging.error(f"‚ùå Failed to load master prompt: {str(e)}")
            # Fallback (simplified but preserving core logic)
            self.master_prompt = "ROLE: CEKA SOVEREIGN MIND. MISSION: TRANSFORM DATA INTO CIVIC INTELLIGENCE. GO HAM."

    def execute_cov_loop(self, raw_input: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        Executes the Chain of Verification (COV) loop as defined in the Master Prompt.
        Ensures factual integrity thresholds are met.
        """
        logging.info(f"üß† Initiating COV Loop for: {raw_input.get('title')}")
        
        payload = {
            "contents": [{
                "parts": [{
                    "text": f"SYSTEM_PROMPT: {self.master_prompt}\n\nINPUT_PAYLOAD: {json.dumps(raw_input)}\n\nMISSION: EXECUTE CHAIN OF VERIFICATION."
                }]
            }],
            "generationConfig": {
                "temperature": 0.2, # Low temperature for factual absolutism
                "topP": 0.95,
                "topK": 40,
                "maxOutputTokens": 4096,
            }
        }

        try:
            response = requests.post(self.api_url, json=payload, headers={'Content-Type': 'application/json'})
            response.raise_for_status()
            result = response.json()
            
            raw_text = result['candidates'][0]['content']['parts'][0]['text']
            
            # Parsing the output into Content + Attuned Metadata
            # The prompt requires metadata in <!-- CEKA_META { ... } -->
            parsed_result = self._parse_attuned_output(raw_text)
            
            if not parsed_result:
                logging.warning("‚ö†Ô∏è Output failed attunement parsing. Retrying reasoning...")
                return None # In production, this would trigger Part C: Regeneration Policy

            if parsed_result['metadata'].get('status') == "RED":
                logging.error("üö® RED STATUS DETECTED: Intelligence aborted due to verification failure.")
                return None
            
            return parsed_result
            
        except Exception as e:
            logging.error(f"‚ùå Execution failure: {str(e)}")
            return None

    def _parse_attuned_output(self, text: str) -> Optional[Dict[str, Any]]:
        """Extracts HTML content and the CEKA_META JSON block."""
        try:
            # Look for the metadata block
            if "<!-- CEKA_META" in text:
                parts = text.split("<!-- CEKA_META")
                html_content = parts[0].strip()
                meta_raw = parts[1].split("-->")[0].strip()
                metadata = json.loads(meta_raw)
                
                return {
                    "content": html_content,
                    "metadata": metadata,
                    "title": metadata.get("title", "Untitled Intelligence")
                }
            return None
        except Exception as e:
            logging.error(f"‚ùå Parsing failure: {str(e)}")
            return None

    def process_queue(self, inputs: List[Dict[str, Any]]):
        logging.info(f"üöÄ Processing {len(inputs)} intelligence units.")
        verified_results = []
        
        for item in inputs:
            result = self.execute_cov_loop(item)
            if result:
                verified_results.append(result)
        
        if verified_results:
            self._write_sql_feed(verified_results)
            logging.info(f"‚úÖ Attuned Intelligence Feed generated: {len(verified_results)} units.")

    def _write_sql_feed(self, results: List[Dict[str, Any]]):
        header = """-- CEKA ATTUNED INTELLIGENCE FEED
-- Generated: {}
INSERT INTO public.generated_articles 
(title, excerpt, content, status, analysis_score, verification_metrics, author)
VALUES
""".format(datetime.now().isoformat())

        rows = []
        for res in results:
            meta = res['metadata']
            title = res['title'].replace("'", "''")
            content = res['content'].replace("'", "''")
            status = 'draft' # Staged for Admin Review
            score = int(meta.get('factual_integrity', 0) * 100)
            metrics = json.dumps(meta).replace("'", "''")
            author = "CEKA"
            excerpt = f"Intelligence unit verified with score {score}%. Authoritative source: {meta.get('sources_consulted', ['Unknown'])[0]}".replace("'", "''")
            
            rows.append(f"('{title}', '{excerpt}', '{content}', '{status}', {score}, '{metrics}'::jsonb, '{author}')")

        body = ",\n".join(rows)
        footer = "\nON CONFLICT (title) DO NOTHING;"
        
        with open(self.output_sql, 'w', encoding='utf-8') as f:
            f.write(header + body + footer)

if __name__ == "__main__":
    # Integration Point: API_KEY should be passed from environment
    API_KEY = os.getenv("GEMINI_API_KEY", "API_KEY_REQUIRED")
    
    ENGINE = AttunedSynchronizer(api_key=API_KEY)
    
    # Sample Mock Input (In production, these come from the Ingestion Scraper)
    SAMPLE_INPUTS = [
        {
            "id": str(uuid.uuid4()),
            "title": "Public Participation Guidelines 2026",
            "text": "The Ministry of Interior has released new guidelines for public participation in county budget processes...",
            "source_id": "GOV-interior-20260211"
        }
    ]
    
    ENGINE.process_queue(SAMPLE_INPUTS)
